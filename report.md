# 实验三：GC 的开销测试和分析

计63 陈晟祺 2016010981

## 实验要求

本实验要求对比一个 Go 语言编写的 WordCount 程序在 GC 开启/关闭的情况下的性能指标，分析 GC 带来的影响；同时，需要实现其他的内存管理方法（手动/引用计数），以分析它们的不同开销。

## 实验环境

本实验使用的环境为：

* 操作系统：Debian 9.11
* 内核：Linux 4.19.0.0-0.bpo.6-amd64
* CPU: Intel Xeon E5-2699 v4 (2.20 GHz) x 2
* RAM: DDR-4 2400 MHz 16GB x 16
* 编译器：gcc 6.3.0, go 1.13.5

## Go 垃圾回收分析

在下列测试中，我们均使用 `wiki0.01.txt` 作为数据集。结果如下：

| 限制线程 | GC 开关 | User Time | Sys Time | Wall Time | Mem Usage | Cache Miss Rate |
| -------- | ------- | --------- | -------- | --------- | --------- | --------------- |
| 1        | on      | 54.79     | 1.62     | 56.35     | 4392568   | 60.206 %        |
| 1        | off     | 33.30     | 12.17    | 45.42     | 24783860  | 16.174 %        |
| 不限     | on      | 102.84    | 1.80     | 50.10     | 2883284   | 59.434 %        |
| 不限     | off     | 33.84     | 12.18    | 45.97     | 24783020  | 16.223 %        |

其中，Cache Miss Rate 由 `perf` 工具测得（指 LLC），其余指标均由 `/usr/bin/time` 工具测得。

我们可以观察到，在限制单线程工作的情况下，打开 GC 后带来了大约 33%（11s） 的总体 overhead，而 GC 的 pause time 约在 23s 左右（即与关闭 GC 时 user time 的差）；此时程序 sys time 显著降低（因为内存分配减少了），内存占用也只有原来的 20% 左右；然而，由于 GC 的代码中断了原有代码的执行，因此 cache 缺失率显著升高，破坏了程序原有的 locality。

在不限制线程时，不打开 GC 时各个指标与单线程几乎相同（因为此时并没有其他的工作）。而打开 GC 给总运行时间带来的 overhead 减小到了 15%（5s） 左右，即 pause time 在 17s 左右，事实上所有的工作线程占用的 CPU Time 达到了原来的三倍左右。可以观察到 GC worker 的增加使得最大的内存占用进一步下降到了单线程时的一半左右（是关闭 GC 时的 10%）。在 cache 缺失率上，与单线程也是类似的。

可见，Go 的 GC 并不会带来太大的总体 overhead。一方面，GC 减少了频繁分配内存带来的特权态切换等额外开销；另一方面，新版本的 Go 的 GC 在 GC 方面进行了较大的改进，增强了并行性，并尽量减少 stop the world 的时间。但不可避免地，GC 会导致 locality 的破环，包括数据和指令方面。

## 其他内存管理机制比较

我们使用 C++ ，分别在不同的内存管理机制下，编写与 `WordCount.go` 相同语义的程序（特别是内存分配上），比较它们的开销。具体地，我们实现了以下的四个版本：

1. （引用计数，`shared_ptr`）使用 `std::shared_ptr<std::string>` 
2. （引用计数，`refcount`）使用自行编写的一个类似 `shared_ptr` 的工具类，并记录引用计数变化的次数
3. （不主动管理，`manual`）在所有位置使用 `std::string`
4. （手动管理，`silly`）在所有位置使用 `std::string*`，并显式地进行 `new/delete`

同样进行类似的测试（均使用 Intel VTune Amplifier 测得），指标如下：

|      | User  | Sys  | Wall  | `new/delete` Time | `new/free` Ratio | Cache Miss | Mem Usage |
| ---- | ----- | ---- | ----- | ----------------- | ---------------- | ---------- | --------- |
| 1    | 20.18 | 1.98 | 22.17 | 5.772             | 26.04%           | 54.391 %   | 3279028   |
| 2    | 22.10 | 2.33 | 24.44 | 5.266             | 23.82%           | 51.222 %   | 3860644   |
| 3    | 19.27 | 0.77 | 20.04 | 4.028             | 20.90%           | 40.612 %   | 1832576   |
| 4    | 16.12 | 0.63 | 16.75 | 7.962             | 49.39%           | 46.698 %   | 1524508   |

可以看到，无论在整体时间还是内存占用上，不管理和手动管理的两个方案均优于引用计数，这是由于引用技术需要维护每个对象的计数并进行额外判断，无论是时间、空间上都有额外的开销，也带来了 cache 缺失率的提升。通过自行实现的引用计数类进行统计，可知所有对象的引用计数总共增加了 269527652 次，减少了 251532747 次：这两个数值的差 17994905 即为最后存在引用数量，恰好等于程序执行到最后的所有字符串引用，也就是 filtered words + different words 的数量，这也说明我们的引用计数实现是正确的。完全使用指针进行手动管理带来的 `new/free` 时间是最长的，但是其总运行时间最短，占用内存也最少；这说明引用计数能虽然减少内存管理操作的数量，但其额外开销比较高，控制粒度也并不精细。如果有更多的线程参与，引用计数由于需要原子操作以进行同步，带来的开销将进一步提高。

需要注意到的是，直接使用 `std::string` 要劣于使用指针手动管理，这可能是由于 `std::string` 的内部实现导致的，如其可能本身具有小字符串优化、字符串池等操作，也未必均在堆上分配内存（其内存管理时间明显更短），因此行为未必是预期的，可能反而带来额外的开销。在两个引用计数的性能比较上，虽然进行了更多的内存管理操作（本质上是因为内部结构更复杂），`std::shared_ptr` 也要优于我们自行实现的引用计数，这是由于我们的实现中跟踪操作数量引入了多余的访存操作；同时，在空间布局的利用上，`shared_ptr` 也更为紧凑。

## 实验结论

通过上述的实现，我们可以知道，手动管理内存能够对内存进行最为精细的控制，往往在时间和空间使用上都有较高的优势；但是其实现复杂，难度较高。在内存的自动管理上，引用计数和垃圾收集是两种不同的方案；引用计数会在每次对象变化时进行统计和检查，而 GC 需要周期性暂停程序进行回收。在实验中，我们可以看到 Go 的 GC 相对于不进行管理带来的额外开销并不大，而能够节省大量的内存。而在 C++ 方面，由于语言标准库的 RAII 特性（它本质上是基于生命周期的手动管理），不主动进行管理事实上也能够达到媲美完全手动管理达到的内存和空间占用；相反地，使用引用计数反而带来了较大的开销。事实上，我们应该根据语言特性（如是否有托管内存、是否使用虚拟机、是否有类似 RAII 的特性）和应用场景来选择合适的内存管理方法，从而取得更优的性能。